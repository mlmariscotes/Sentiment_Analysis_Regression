{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33043711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # regular expression\n",
    "import nltk # natural language tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d5cc323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spend your money elsewhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Their regular toasted bread was equally satisf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Buffet at Bellagio was far from what I ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the drinks are WEAK, people!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#NAME?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0                        Spend your money elsewhere.\n",
       "1  Their regular toasted bread was equally satisf...\n",
       "2  The Buffet at Bellagio was far from what I ant...\n",
       "3                   And the drinks are WEAK, people!\n",
       "4                                             #NAME?"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('a2_RestaurantReviews_FreshDump.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb64d689",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e89ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ext.mark.mariscotes\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords # removing commong words\n",
    "from nltk.stem.porter import PorterStemmer # reducing words (stemming)\n",
    "ps = PorterStemmer()\n",
    "\n",
    "all_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35bad4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "# Loop through each row in the dataset until there's no data left\n",
    "i = 0\n",
    "while i < len(df) and df['Review'][i]:\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1647b86c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spend money elsewher',\n",
       " 'regular toast bread equal satisfi occasion pat butter mmmm',\n",
       " 'buffet bellagio far anticip',\n",
       " 'drink weak peopl',\n",
       " 'name',\n",
       " 'also feel like chip bought made hous',\n",
       " 'disappoint dinner went elsewher dessert',\n",
       " 'chip sal amaz',\n",
       " 'return',\n",
       " 'new fav vega buffet spot',\n",
       " 'serious cannot believ owner mani unexperienc employe run around like chicken head cut',\n",
       " 'sad',\n",
       " 'felt insult disrespect could talk judg anoth human like',\n",
       " 'call steakhous properli cook steak understand',\n",
       " 'impress concept food',\n",
       " 'thing crazi guacamol like pur ed',\n",
       " 'realli noth postino hope experi better',\n",
       " 'got food poison buffet',\n",
       " 'brought fresh batch fri think yay someth warm',\n",
       " 'hilari yummi christma eve dinner rememb biggest fail entir trip us',\n",
       " 'needless say go back anytim soon',\n",
       " 'place disgust',\n",
       " 'everi time eat see care teamwork profession degre',\n",
       " 'ri style calamari joke',\n",
       " 'howev much garlic fondu bare edibl',\n",
       " 'could bare stomach meal complain busi lunch',\n",
       " 'bad lost heart finish',\n",
       " 'also took forev bring us check ask',\n",
       " 'one make scene restaur get definit lost love one',\n",
       " 'disappoint experi',\n",
       " 'food par denni say good',\n",
       " 'want wait mediocr food downright terribl servic place',\n",
       " 'waaaaaayyyyyyyyyi rate say',\n",
       " 'go back',\n",
       " 'place fairli clean food simpli worth',\n",
       " 'place lack style',\n",
       " 'sangria half glass wine full ridicul',\n",
       " 'bother come',\n",
       " 'meat pretti dri slice brisket pull pork',\n",
       " 'build seem pretti neat bathroom pretti trippi eat',\n",
       " 'equal aw',\n",
       " 'probabl hurri go back',\n",
       " 'slow seat even reserv',\n",
       " 'good stretch imagin',\n",
       " 'cashew cream sauc bland veget undercook',\n",
       " 'chipolt ranch dip saus tasteless seem thin water heat',\n",
       " 'bit sweet realli spici enough lack flavor',\n",
       " 'disappoint',\n",
       " 'place horribl way overpr',\n",
       " 'mayb vegetarian fare twice thought averag best',\n",
       " 'busi know',\n",
       " 'tabl outsid also dirti lot time worker alway friendli help menu',\n",
       " 'ambianc feel like buffet set douchey indoor garden tea biscuit',\n",
       " 'con spotti servic',\n",
       " 'fri hot neither burger',\n",
       " 'came back cold',\n",
       " 'food came disappoint ensu',\n",
       " 'real disappoint waiter',\n",
       " 'husband said rude even apolog bad food anyth',\n",
       " 'reason eat would fill night bing drink get carb stomach',\n",
       " 'insult profound deuchebaggeri go outsid smoke break serv solidifi',\n",
       " 'someon order two taco think may part custom servic ask combo ala cart',\n",
       " 'quit disappoint although blame need place door',\n",
       " 'rave review wait eat disappoint',\n",
       " 'del taco pretti nasti avoid possibl',\n",
       " 'hard make decent hamburg',\n",
       " 'like',\n",
       " 'hell go back',\n",
       " 'gotten much better servic pizza place next door servic receiv restaur',\n",
       " 'know big deal place back ya',\n",
       " 'immedi said want talk manag want talk guy shot firebal behind bar',\n",
       " 'ambianc much better',\n",
       " 'unfortun set us disapppoint entre',\n",
       " 'food good',\n",
       " 'server suck wait correct server heimer suck',\n",
       " 'happen next pretti put',\n",
       " 'bad caus know famili own realli want like place',\n",
       " 'overpr get',\n",
       " 'vomit bathroom mid lunch',\n",
       " 'kept look time soon becom minut yet still food',\n",
       " 'place eat circumst would ever return top list',\n",
       " 'start tuna sashimi brownish color obvious fresh',\n",
       " 'food averag',\n",
       " 'sure beat nacho movi would expect littl bit come restaur',\n",
       " 'ha long bay bit flop',\n",
       " 'problem charg sandwich bigger subway sub offer better amount veget',\n",
       " 'shrimp unwrap live mile brushfir liter ice cold',\n",
       " 'lack flavor seem undercook dri',\n",
       " 'realli impress place close',\n",
       " 'would avoid place stay mirag',\n",
       " 'refri bean came meal dri crusti food bland',\n",
       " 'spend money time place els',\n",
       " 'ladi tabl next us found live green caterpillar salad',\n",
       " 'present food aw',\n",
       " 'tell disappoint',\n",
       " 'think food flavor textur lack',\n",
       " 'appetit instantli gone',\n",
       " 'overal impress would go back',\n",
       " 'whole experi underwhelm think go ninja sushi next time',\n",
       " 'wast enough life pour salt wound draw time took bring check']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba252e",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "492f29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading BoW dictionary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "cvFile='c1_BoW_Sentiment_Model.pkl'\n",
    "cv = pickle.load(open(cvFile, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7df564f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1420)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fresh = cv.transform(corpus).toarray()\n",
    "X_fresh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5240f5",
   "metadata": {},
   "source": [
    "### Prediction (via Sentiment Classifier = c1_Bow_Sentiment_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f2aaa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "classifier = joblib.load('c2_Classifier_Sentiment_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6a4733e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_fresh)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "833e096d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spend your money elsewhere.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Their regular toasted bread was equally satisf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Buffet at Bellagio was far from what I ant...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the drinks are WEAK, people!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  predicted_label\n",
       "0                        Spend your money elsewhere.                0\n",
       "1  Their regular toasted bread was equally satisf...                1\n",
       "2  The Buffet at Bellagio was far from what I ant...                1\n",
       "3                   And the drinks are WEAK, people!                0\n",
       "4                                             #NAME?                1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predicted_label'] = y_pred.tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0401773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('predicted_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
